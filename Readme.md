# Lunaconf 2024 demo for AI with Scala - An Intro to Lanchain 4j

### Prerequisite

#### For MacOS

#### Install ollama
`brew install ollamma`

#### Pull the models required to run this demo
`ollamma pull gemma2:9b`

`ollamma pull llama3.1`

`ollamma pull all-minilm`

#### Start the ollama inference server
`ollamma serve`

### Running the application
`sbt`

#### When in the sbt terminal execute run <demo_number>
`run 1`


## TODOs

1. Change the reference of veloria.txt from using absolute path to use a relative path from the resources
